{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9274f94c",
   "metadata": {},
   "source": [
    "# 4.1 Importance of Memory Access Efficiency\n",
    "<img src=\"resources/Fig4.1.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "In the code snippet above, the global memory access fetches an ```in[]``` array element. The floating-point add op accumulates the value of ```int[]``` into ```pixVal```. Thus, the ratio of FP op to global memory access is **one** FP op to **one** memory access. This ratio is referred as: the ***compute-to-global-memory-access ratio***. \n",
    "\n",
    "* **compute-to-global-memory-access ratio**: the number of floating-point calculation performed for each access to the global memory within a region of a program\n",
    "\n",
    "**compute-to-global-memory-access ratio** implies the performance of a CUDA kernel. Considering a device: \n",
    "* 1000GB/s global memory bandwidth; 4bytes in each single precision FP value.\n",
    "* Peak single-precision performance of: 12TFLOPS (floating point operations persecond)\n",
    "\n",
    "Max number FP value can be loaded per second will be: ```1000GB / 4B = 250G```\n",
    "To achieve peak. SP-floating point performace, we need a **compute-to-global-memory-access ratio** of ```12T/250G = 48```.\n",
    "\n",
    "Goal is to **reduce the number of global memory accesses** when possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561088ea",
   "metadata": {},
   "source": [
    "# 4.2 Matrix Multiplication (Naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5eb25b",
   "metadata": {},
   "source": [
    "## a. Naive Matrix Multiplication arithmetic\n",
    "<img src=\"resources/Fig4.2.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "<img src=\"resources/Fig4.3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991e31f",
   "metadata": {},
   "source": [
    "**Considering MatMult**: $$C = M \\times N$$\n",
    "\n",
    "**Row, Col indexes** for **P(Row, Col)** element could be accessed using: \n",
    "$$ Col = threadIdx.x + blockIdx.x * blockDim.x   $$\n",
    "$$ Row = threadIdx.y + blockIdx.y * blockDim.y   $$\n",
    "\n",
    "**The value of P(Row, Col)** is the inner product of $Row^{th}$ row of **M** and $Col^{th}$ col of **N**\n",
    "$$ P_{value} = \\sum \\limits_{k=0}^{Width-1} M_{Row, k} * N_{k, Col} %$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb92bf",
   "metadata": {},
   "source": [
    "## b. Map 2D matrix to 1D memory arrays\n",
    "Pixel in 2D matrix: $$ M_{Row_{idx}, Col_{idx}} $$ is mapped to 1D memory array\n",
    "\n",
    "$$  M[Row_{idx} * Width + Col_{idx}] $$\n",
    "\n",
    "Recall MatMult Equation: $$ P_{value} = \\sum \\limits_{k=0}^{Width-1} M_{Row, k} * N_{k, Col}$$\n",
    "\n",
    "```M[Row, k]``` and ```M[k, Col]``` could be mapped to: \n",
    "\n",
    "* $$M_{Row, k} \\space is \\space mapped \\space to \\space M[Row * Width + k]$$\n",
    "* $$M_{k, Col} \\space is \\space mapped \\space to \\space M[k * Width + Col]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b956ae",
   "metadata": {},
   "source": [
    "## C. MatMult Kernel illustration\n",
    "\n",
    "* $4\\times4$ **M**, $4\\times4$ **N**, and the result is $4\\times4$ **P**\n",
    "\n",
    "* CUDA configs are: $2 \\times 2 $ ```Blocks```, resulting a $2 \\times 2 $ ```Grid```. This grid fits the result matrix: **P**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb971309",
   "metadata": {},
   "source": [
    "<img src=\"resources/Fig4.4.png\" alt=\"Drawing\" style=\"width: 350px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad75d8e",
   "metadata": {},
   "source": [
    "**P is mapped to the blocks model above:**\n",
    "\n",
    "```Thread(0, 0) of block(0, 0)``` computes $P_{0, 0}$, ```Thread(0, 1) of block(1, 1)``` computes $P_{2, 3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba9250",
   "metadata": {},
   "source": [
    "<img src=\"resources/Fig4.3.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<img src=\"resources/Fig4.5.png\" alt=\"Drawing\" style=\"width: 350px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ba8a6",
   "metadata": {},
   "source": [
    "### Walk through for-loop for thread(1, 1) in bock(1, 0), i.e, Compute $P[3][1]$, Using values of $M[3, :] and N[:, 1]$\n",
    "* $0^{th}$ iteration: \n",
    " * **M:** $Row \\times Width + k = 3 \\times 4 + 0 = 12$, Accessing $M[12]$\n",
    " * **N:** $k \\times Width + Col = 0 \\times 4 + 1 = 1$, Accessing $N[1]$\n",
    "* $1^{st}$ iteration\n",
    " * **M:** $Row \\times Width + k = 3 \\times 4 + 1 = 13$, Accessing $M[13]$\n",
    " * **N:** $k \\times Width + Col = 1 \\times 4 + 1 = 5$, Accessing $N[5]$\n",
    "* $2^{nd}$ iteration\n",
    " * **M:** $Row \\times Width + k = 3 \\times 4 + 2 = 12$, Accessing $M[14]$\n",
    " * **N:** $k \\times Width + Col = 2 \\times 4 + 1 = 1$, Accessing $N[9]$\n",
    "* $3^{rd}$ iteration\n",
    " * **M:** $Row \\times Width + k = 3 \\times 4 + 3 = 15$, Accessing $M[15]$\n",
    " * **N:** $k \\times Width + Col = 3 \\times 4 + 1 = 13$, Accessing $N[13]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9795e39",
   "metadata": {},
   "source": [
    "# 4.3 CUDA Memory Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e95188",
   "metadata": {},
   "source": [
    "<img src=\"resources/Fig4.6.png\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b0391",
   "metadata": {},
   "source": [
    "CUDA devices also have roots in Von Neumann Models. \n",
    "\n",
    "**Shared memory** are accessible by **all** threads in a block, whereas register data are **private** to a thread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61a575d",
   "metadata": {},
   "source": [
    "<img src=\"resources/Fig4.8.png\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5936e10",
   "metadata": {},
   "source": [
    "As shown above, SM typically employs multiple processing units, to allow threads make simultaneous progress. Therefore, the hardware implementations of shared memory in these CUDA devices are typically designed to allow multiple processing units to simultaneously access its contents to support data sharing among threads in a block. \n",
    "\n",
    "CUDA devices is an SIMD design, each thread is a Von Neumann model. All of these threads shares the same PC and IR. Under this design, all threads make simultaneous progress by executing the same instruction in the program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a2a70a",
   "metadata": {},
   "source": [
    "# 4.4 Tiling for Reduced Memory Traffic\n",
    "\n",
    "## Recall the naive MxM example and its memory access pattern:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb6854",
   "metadata": {},
   "source": [
    "<img src=\"resources/Fig4.5.png\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "<img src=\"resources/Fig4.10.png\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5650a8",
   "metadata": {},
   "source": [
    "In the example given above: A significant overalp occurs in the M and N elements they access.\n",
    "\n",
    "* T(0, 0), T(0, 1) access the row 0 in M\n",
    "* T(1, 0), T(1, 1) access the row 1 in M\n",
    "* T(0, 0), T(1, 0) access the col 0 in M\n",
    "* T(0, 1), T(1, 1) access the col 1 in N\n",
    "\n",
    "If these threads can collaborate and share the M, N loaded from global memory. Global memory Traffic could be **reduced** by **half**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b4596",
   "metadata": {},
   "source": [
    "## To utilize the potential traffic reduction, additional execution schedule is required so data accesses can be combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816eb65d",
   "metadata": {},
   "source": [
    "In the context of paralell computing, **Tiling** is a program transformation technique that localizes the memory locations accessed among threads and the timing of their accesses. \n",
    "\n",
    "**Tiling** divides the long access sequences of each thread into phases and uses barrier synchronization to keep the timing of accesses to each section at close intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13dc6d",
   "metadata": {},
   "source": [
    "## Tiled matrix multiplication algorithm\n",
    "\n",
    "The basic idea of **tileMxM** is for the ```threads``` to collaboratively load subsets of **M** and **N** into the ***shared memory*** before they individually use these elements in their dot product calculation. \n",
    "\n",
    "The size of shared memory is small and the capcity of the shared memory **should not be exceeded** when these elements are loaded. This constraint can be satisfied **by dividing the M and N into smaller tiles**. \n",
    "\n",
    "For example, $4\\times4$ matrices are divided into $2\\times2$ tiles in the following example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe10a82",
   "metadata": {},
   "source": [
    "<img src=\"resources/Fig4.14.png\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "<img src=\"resources/Fig4.15.png\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab03e3e",
   "metadata": {},
   "source": [
    "As shown above: the dot product calculations performed by **each thread** are now divided into **phases**. \n",
    "\n",
    "The shared memory array for **M** elements are called **Mds**, similiar to **Nds**\n",
    "\n",
    "### 1. At the beginning of **Phase1** \n",
    "* The four threads of ```block(0, 0)``` load a tile of M into a shared memory\n",
    " * T(0, 0) loads M(0, 0) into $Mds[0][0]$\n",
    " * T(0, 1) loads M(0, 1) into $Mds[0][1]$\n",
    " * T(1, 0) loads M(1, 0) into $Mds[1][0]$\n",
    " * T(1, 1) loads M(1, 1) into $Mds[1][1]$\n",
    "* similiarly, the four threads of ```block(0, 0)``` load a tile of N into a shared memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a35be0",
   "metadata": {},
   "source": [
    "### 2. After M, N tiles are loaded into the shared Memory\n",
    "These elements are used in the calcuation of the dot product. Each value in the shared memory are used twice; e.g., the **M(1, 1)** value loaded into $Mds[1][1]$ is used by ```T(1, 0)``` and ```T(1, 1)```. Therefore, the number of accesses to global memory is reduced by half. \n",
    "\n",
    "The **reduction factor** will be N if the tiles are $N\\times N$ elements.\n",
    "\n",
    "**Note** that the calculation of each dot product between ```M[row], N[col]```is now performed in two phases. Pvalues are accumulated in each phase. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07675727",
   "metadata": {},
   "source": [
    "### 3. Gerneralize the example shown above\n",
    "\n",
    "Given a matrix of $Width\\times Width$, tile size of ```TILE_WIDTH```. \n",
    "The dot product would be performed in $\\frac{Width} {TILE\\_WIDTH}$ phases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce868c7",
   "metadata": {},
   "source": [
    "# 4.5 A tiled matrix Multiplication Kernel\n",
    "<img src=\"resources/Fig4.17.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "<img src=\"resources/Fig4.16.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6abdb5",
   "metadata": {},
   "source": [
    "Theoratically, tiled algorithm provides benefit that reduce the global memory accesses by a factor of ```TILE_WIDTH```. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72886233",
   "metadata": {},
   "source": [
    "# 4.6 Boundary Checks\n",
    "This section Extend the tiled matrix multiplication to handle matrices with **arbitary widths**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf5039",
   "metadata": {},
   "source": [
    "<img src=\"resources/Fig4.20.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0fd597",
   "metadata": {},
   "source": [
    "# 4.7 Memory as a Limiting factor to Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a0106",
   "metadata": {},
   "source": [
    "## Example: Device Query of RTX3070\n",
    "\n",
    "```sh\n",
    "CUDA Device Query (Runtime API) version (CUDART static linking)\n",
    "\n",
    "Detected 1 CUDA Capable device(s)\n",
    "\n",
    "Device 0: \"NVIDIA GeForce RTX 3070\"\n",
    "  CUDA Driver Version / Runtime Version          11.6 / 11.4\n",
    "  CUDA Capability Major/Minor version number:    8.6\n",
    "  Total amount of global memory:                 8192 MBytes (8589410304 bytes)\n",
    "  (046) Multiprocessors, (128) CUDA Cores/MP:    5888 CUDA Cores\n",
    "  GPU Max Clock rate:                            1725 MHz (1.73 GHz)\n",
    "  Memory Clock rate:                             7001 Mhz\n",
    "  Memory Bus Width:                              256-bit\n",
    "  L2 Cache Size:                                 4194304 bytes\n",
    "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
    "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
    "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
    "  Total amount of constant memory:               65536 bytes\n",
    "  Total amount of shared memory per block:       49152 bytes\n",
    "  Total shared memory per multiprocessor:        102400 bytes\n",
    "  Total number of registers available per block: 65536\n",
    "  Warp size:                                     32\n",
    "  Maximum number of threads per multiprocessor:  1536\n",
    "  Maximum number of threads per block:           1024\n",
    "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
    "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
    "  Maximum memory pitch:                          2147483647 bytes\n",
    "  Texture alignment:                             512 bytes\n",
    "  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n",
    "  Run time limit on kernels:                     Yes\n",
    "  Integrated GPU sharing Host Memory:            No\n",
    "  Support host page-locked memory mapping:       Yes\n",
    "  Alignment requirement for Surfaces:            Yes\n",
    "  Device has ECC support:                        Disabled\n",
    "  Device supports Unified Addressing (UVA):      Yes\n",
    "  Device supports Managed Memory:                Yes\n",
    "  Device supports Compute Preemption:            Yes\n",
    "  Supports Cooperative Kernel Launch:            Yes\n",
    "  Supports MultiDevice Co-op Kernel Launch:      No\n",
    "  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n",
    "  Compute Mode:\n",
    "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
    "\n",
    "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.6, CUDA Runtime Version = 11.4, NumDevs = 1\n",
    "Result = PASS\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee837c9",
   "metadata": {},
   "source": [
    "My device can accommodate:\n",
    "* For each SM: 1536 threads, and 65536 registers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++11",
   "language": "C++11",
   "name": "xcpp11"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
